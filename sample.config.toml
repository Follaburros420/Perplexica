[GENERAL]
SIMILARITY_MEASURE = "cosine" # "cosine" or "dot"
KEEP_ALIVE = "5m" # How long to keep Ollama models loaded into memory. (Instead of using -1 use "-1m")

[MODELS.OPENAI]
API_KEY = ""

[MODELS.GROQ]
API_KEY = ""

[MODELS.ANTHROPIC]
API_KEY = ""

[MODELS.GEMINI]
API_KEY = ""

[MODELS.CUSTOM_OPENAI]
API_KEY = "dummy-key" # vLLM no requiere API key real, pero el campo no puede estar vac√≠o
API_URL = "http://host.docker.internal:8000/v1" # URL de tu contenedor vLLM
MODEL_NAME = "gpt-oss-20b" # Nombre de tu modelo

[MODELS.OLLAMA]
API_URL = "" # Ollama API URL - http://host.docker.internal:11434

[MODELS.DEEPSEEK]
API_KEY = ""

[MODELS.AIMLAPI]
API_KEY = "" # Required to use AI/ML API chat and embedding models

[MODELS.LM_STUDIO]
API_URL = "" # LM Studio API URL - http://host.docker.internal:1234

[API_ENDPOINTS]
SEARXNG = "" # SearxNG API URL - http://localhost:32768
